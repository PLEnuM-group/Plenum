{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../core\")\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy.interpolate import RegularGridInterpolator, splrep, splev, InterpolatedUnivariateSpline\n",
    "from scipy.stats import chi2, gaussian_kde, norm\n",
    "from scipy.special import erfinv, erf\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from copy import deepcopy\n",
    "import healpy as hp\n",
    "import gc\n",
    "gc.enable()\n",
    "from settings import *\n",
    "from tools import get_mids\n",
    "from aeff_calculations import energy_smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LIVETIME)\n",
    "print(GAMMA_ASTRO)\n",
    "print(PHI_ASTRO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the effective areas based on \"alternative_plenum_aeff.ipynb\"\n",
    "\n",
    "We use here only upgoing events with dec>-5deg, since this is the threshold for a pure data set with few muons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only upgoing data to mimick up-going muon track data set\n",
    "with open(\"../resources/tabulated_logE_sindec_aeff_upgoing.pckl\", \"rb\") as f:\n",
    "    log_ebins, sindec_bins, aeff_2d = pickle.load(f)\n",
    "\n",
    "log_emids = get_mids(log_ebins)\n",
    "ebins = np.power(10, log_ebins)\n",
    "emids = get_mids(ebins)\n",
    "ewidth = np.diff(ebins)\n",
    "\n",
    "sindec_mids = get_mids(sindec_bins)\n",
    "sindec_width = np.diff(sindec_bins)\n",
    "\n",
    "ra_bins = np.linspace(0, np.pi*2, num=101)\n",
    "ra_mids = (ra_bins[1:] + ra_bins[:-1]) * 0.5\n",
    "ra_width = ra_bins[1:] - ra_bins[:-1]\n",
    "print(len(emids), \"log_10(energy) bins\")\n",
    "print(len(sindec_mids), \"declination bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here, we use \"Plenum-1\" with 10yr IceCube and 10yr PLENUM with IceCube\n",
    "= baseline PLENUM + 10yr IceCube\n",
    "### and \"Plenum-2\" with 10yr IceCube and 10yr PLENUM with GEN2\n",
    "= baseline PLENUM (includes 10yr IceCube) + 10yr GEN2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCEQ\n",
    "with open(\"../resources/MCEq_flux.pckl\", \"rb\") as f:\n",
    "    (e_grid, zen), flux_def = pickle.load(f)\n",
    "rgi = RegularGridInterpolator(\n",
    "    (e_grid, -np.cos(np.deg2rad(zen))), \n",
    "    np.log(flux_def['numu_conv'])\n",
    ")\n",
    "ee, ss = np.meshgrid(emids, sindec_mids)\n",
    "spl_vals = np.exp(rgi((ee, ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Icecube energy x sindec\n",
    "### comparison to diffuse (only northern) should yield ~600k events, ~2700 astro for a livetime of 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeff_calculations import aeff_eval_e_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "for det in [\"IceCube\", \"Plenum-1\"]:\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[det], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    astro_ev = aeff_factor * (emids/E_NORM)**(-GAMMA_ASTRO) * PHI_ASTRO\n",
    "    atm_ev = aeff_factor * spl_vals\n",
    "\n",
    "    print(det)\n",
    "    print(\"conv events:\", np.sum(atm_ev))\n",
    "    print(\"astro events:\", np.sum(astro_ev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# energy smearing with KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resources/energy_smearing_kde.pckl\", \"rb\") as f:\n",
    "    kvals = pickle.load(f)\n",
    "# normalize per bin in true energy\n",
    "normed_kvals = kvals/np.sum(kvals, axis=0)\n",
    "\n",
    "eri = get_mids(np.arange(0.5, 9, 0.2))\n",
    "# log_emids are the same as for effective area binning\n",
    "ee, rr = np.meshgrid(log_emids, eri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(\n",
    "    ee,\n",
    "    rr,\n",
    "    kvals\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.plot([1, 9], [1, 9], color=\"tab:orange\")\n",
    "plt.ylim(np.min(rr), np.max(rr))\n",
    "plt.xlim(np.min(ee), np.max(ee))\n",
    "plt.title(\"KDE reproduction of E-smearing\")\n",
    "plt.ylabel(\"log(E reco (muon) / GeV)\")\n",
    "plt.xlabel(\"log(E true (neutrino) / GeV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nice plot of expected astro events with energy smearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeff_factor = aeff_eval_e_sd(\n",
    "    aeff_2d[\"IceCube\"],\n",
    "    sindec_width, ewidth, ra_width) * LIVETIME\n",
    "astro_ev = energy_smearing(\n",
    "    normed_kvals,\n",
    "    aeff_factor * (emids/E_NORM)**(-GAMMA_ASTRO) * PHI_ASTRO)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "im = ax.pcolormesh(\n",
    "    eri,\n",
    "    sindec_bins,\n",
    "    astro_ev,\n",
    "    norm=LogNorm()\n",
    ")\n",
    "plt.colorbar(im, ax=ax)\n",
    "ax.set_ylim(-0.1, 1)\n",
    "ax.set_xlim(2, 9.2)\n",
    "ax.set_title(\"Astro events\")\n",
    "ax.set_xlabel(r\"$E_{\\rm true}$ / GeV\")\n",
    "ax.set_ylabel(r\"$\\sin(\\delta)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test event numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeff_factor = aeff_eval_e_sd(\n",
    "    aeff_2d[\"IceCube\"],\n",
    "    sindec_width, ewidth, ra_width) * LIVETIME\n",
    "astro_ev = aeff_factor * (emids/E_NORM)**(-GAMMA_ASTRO) * PHI_ASTRO\n",
    "\n",
    "print(\"original sum astro:\", np.sum(astro_ev))\n",
    "print(\"smeared sum astro:\", np.sum(energy_smearing(normed_kvals, astro_ev)), \"(should be numerically the same)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple diffuse flux fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adapted from mauricio's notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adapted from Mauricio's fluxes\n",
    "#### to be moved to separate script\n",
    "\n",
    "# These are the basic shapes\n",
    "def gaussian(x, mu, sigma):\n",
    "    '''Not normalized, then parameters are easier to interpret'''\n",
    "    return np.exp(-(x - mu)**2 / (2 * sigma**2) ) #/(np.sqrt(2*np.pi) * sigma)\n",
    "\n",
    "def power_law(energy, e_scale, gamma, phi0):\n",
    "    return (energy/e_scale)**(-gamma) * phi0\n",
    "\n",
    "def cut_off(energy, e_cut):\n",
    "    return np.exp(-energy/e_cut)\n",
    "\n",
    "def parabola_index(alpha, beta, energy, enorm):\n",
    "    return alpha + beta * np.log10(energy/enorm)\n",
    "\n",
    "def sigmoid(fraction_depletion, growth_rate, energy, energy_nu_trans):\n",
    "    factor = 1 - fraction_depletion\n",
    "    factor /= (1 + np.exp(-growth_rate * (energy - energy_nu_trans)))\n",
    "    factor += fraction_depletion\n",
    "    return factor\n",
    "\n",
    "# combine basic shapes to actual fluxes\n",
    "\n",
    "def astro_flux(shape, aeff_factor, emids, enorm, *args, smear_energy=True):\n",
    "    \"\"\" \n",
    "    Wrapper for different astro flux shapes to put into TS minimizer.\n",
    "    Possible shapes and their parameters:\n",
    "    ° powerlaw:\n",
    "        args[0]: gamma\n",
    "        args[1]: phi scaling\n",
    "    \n",
    "    ° double powerlaw:\n",
    "        args[0]: gamma_1 (E < E_Break)\n",
    "        args[1]: phi scaling\n",
    "        args[2]: gamma_2 (E >= E_Break)\n",
    "        args[3]: E_Break\n",
    "        \n",
    "    ° powerlaw * cutoff:\n",
    "        args[0]: gamma\n",
    "        args[1]: phi scaling\n",
    "        args[2]: cutoff energy\n",
    "        \n",
    "    ° powerlaw * dip/bump:\n",
    "        args[0]: gamma\n",
    "        args[1]: phi scaling\n",
    "        args[2]: amplitude --- sign of amplitude is defined by 'dip' or 'bump'\n",
    "        args[3]: mean energy\n",
    "        args[4]: width\n",
    "        \n",
    "    ° powerlaw * sigmoid:\n",
    "        args[0]: gamma\n",
    "        args[1]: phi scaling\n",
    "        args[2]: fraction of depletion\n",
    "        args[3]: growth rate\n",
    "        args[4]: transition energy\n",
    "        \n",
    "    ° log-parabola:\n",
    "        args[0]: alpha parameter\n",
    "        args[1]: phi scaling\n",
    "        args[2]: beta parameter\n",
    "    \"\"\"\n",
    "    if \"powerlaw\" in shape:\n",
    "        _gamma_astro = args[0]\n",
    "        _phi_astro_scaling = args[1]\n",
    "        tmp =  aeff_factor * power_law(\n",
    "            emids, enorm, _gamma_astro, PHI_0 * _phi_astro_scaling)\n",
    "        \n",
    "    if \"double\" in shape:\n",
    "        _gamma_2 = args[2]\n",
    "        _E_break = np.power(10, args[3])\n",
    "        phi_2 = PHI_0 * _phi_astro_scaling * (_E_break / enorm) ** (-_gamma_astro + _gamma_2)\n",
    "        tmp_2 = aeff_factor * power_law(emids, enorm, _gamma_2, phi_2)\n",
    "        ### merge the two powerlaw shapes\n",
    "        if type(tmp) == np.ndarray or type(tmp) == list:\n",
    "            tmp[:,emids >= _E_break] = tmp_2[:,emids >= _E_break]\n",
    "        elif type(tmp) == float:\n",
    "            if emids >= _E_break:\n",
    "                tmp = tmp_2\n",
    "        else:\n",
    "            raise ValueError(f\"??? invalid type of tmp array ({type(tmp)})\")\n",
    "            \n",
    "        \n",
    "    if \"cutoff\" in shape:\n",
    "        _energy_cut = np.power(10, args[2])\n",
    "        tmp *= cut_off(emids, _energy_cut)\n",
    "        \n",
    "    if \"bump\" in shape or \"dip\" in shape:\n",
    "        amp = np.power(10, args[2])\n",
    "        energy_mean = np.power(10, args[3])\n",
    "        sigma = np.power(10, args[4])\n",
    "        amp = amp if \"bump\" in shape else -1 * amp\n",
    "        tmp *= (1.0 + amp * gaussian(emids, energy_mean, sigma))\n",
    "        \n",
    "    if \"sigmoid\" in shape:\n",
    "        fraction_depletion = np.power(10, args[2])\n",
    "        growth_rate = np.power(10, args[3])\n",
    "        energy_nu_trans = np.power(10, args[4])\n",
    "        tmp *= sigmoid(fraction_depletion, growth_rate, emids, energy_nu_trans)\n",
    "        \n",
    "    if \"parabola\" in shape:\n",
    "        _alpha_astro = args[0]\n",
    "        _phi_astro_scaling = args[1]\n",
    "        _beta_astro = args[2]        \n",
    "        index = parabola_index(_alpha_astro, _beta_astro, emids, enorm)\n",
    "        tmp =  aeff_factor * power_law(\n",
    "            emids, enorm, index, PHI_0 * _phi_astro_scaling)\n",
    "    ## energy smearing\n",
    "    if smear_energy:\n",
    "        tmp = energy_smearing(normed_kvals, tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atmo_background(aeff_factor, spl_vals, smear_energy=True):\n",
    "    if smear_energy:\n",
    "        return energy_smearing(normed_kvals, aeff_factor * spl_vals)\n",
    "    else:\n",
    "        return aeff_factor * spl_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### to be moved to separate script\n",
    "\n",
    "shape_params = {\n",
    "    # parameters from https://arxiv.org/abs/1908.09551\n",
    "    \"powerlaw\": {\n",
    "        \"baseline\": np.array([1, GAMMA_ASTRO, PHI_ASTRO_FACTOR]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0)]),\n",
    "        \"names\": np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\"]),\n",
    "        \"fancy_names\": np.array([\"Conv. scaling\", r\"$\\gamma_{\\rm astro}$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\"])\n",
    "    },\n",
    "    # parameters inspired by https://www.institut3b.physik.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaawyqakk\n",
    "    \"powerlaw with cutoff\": {\n",
    "        \"baseline\": np.array([1, 2.0, 1.5, 6]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (4.5, 8.5)]),\n",
    "        \"names\": np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\", \"Cut_off\"]),\n",
    "        \"fancy_names\": np.array([\"Conv. scaling\", r\"$\\gamma_{\\rm astro}$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\",\n",
    "                  r\"$\\log_{10}$(Cut-off energy/GeV)\"])\n",
    "    },\n",
    "    # parameters inspired by https://www.institut3b.physik.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaawyqakk\n",
    "    \"log-parabola\": {\n",
    "        \"baseline\": np.array([1, 2, 1.7, 0.5]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (0.1, 1.9)]),\n",
    "        \"names\": np.array([\"conv_scaling\", \"alpha\", \"Phi_0\", r\"beta\"]),\n",
    "        \"fancy_names\": np.array([\"Conv. scaling\", r\"$\\alpha$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\", r\"$\\beta$\"])\n",
    "    },\n",
    "    # parameters inspired by https://www.institut3b.physik.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaawyqakk\n",
    "    \"double powerlaw\": {\n",
    "        \"baseline\": np.array([1, 2.0, 1.2, 3.5, np.log10(1E6)]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (1.5, 4.0), (5, 7)]),\n",
    "        \"names\": np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\", \"gamma_2\", \"E_break\"]),\n",
    "        \"fancy_names\": np.array([\"Conv. scaling\", r\"$\\gamma_1$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\"\n",
    "                                r\"$\\gamma_2$\", r\"$E_{\\rm break}$\"])\n",
    "    },\n",
    "    \"powerlaw with sigmoid\": {\n",
    "        \"baseline\": np.array([1, GAMMA_ASTRO, PHI_ASTRO_FACTOR, np.log10(0.1), np.log10(1E-5), np.log10(4E5)]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (-2., 0), (-6, -4), (4.5, 6.5)]),\n",
    "        \"names\": np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\", \"depletion\", \"growth\", \"transition\"]),\n",
    "        \"fancy_names\": np.array([\"Conv. scaling\", r\"$\\gamma_{\\rm astro}$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\",\n",
    "                  \"Depletion fraction\", \"Growth rate\", r\"$\\log_{10}$(Transition energy/GeV)\"])\n",
    "    },\n",
    "    \"powerlaw with dip\": {\n",
    "        \"baseline\": np.array([1, GAMMA_ASTRO, PHI_ASTRO_FACTOR, np.log10(0.7), np.log10(6E5), np.log10(6E5/3)]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (-2., 1), (4., 7.), (3.5, 7.)]),\n",
    "        \"names\":np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\", \"amplitude\", \"mean_energy\", \"width\"]),\n",
    "        \"fancy_names\":np.array([\"Conv. scaling\", r\"$\\gamma_{\\rm astro}$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\",\n",
    "                  \"Amplitude\", r\"$\\log_{10}$(Mean energy/GeV)\", r\"$\\log_{10}$(Width/GeV)\"])\n",
    "    },\n",
    "    \"powerlaw with bump\": {\n",
    "        \"baseline\": np.array([1, GAMMA_ASTRO, PHI_ASTRO_FACTOR, np.log10(2.2), np.log10(4.5E5), np.log10(4.5E5/3)]),\n",
    "        \"bounds\": np.array([(0.9, 1.1), (1.0, 4.0), (0.2, 3.0), (-2., 1), (4., 7.), (3.5, 7.)]),\n",
    "        \"names\":np.array([\"conv_scaling\", \"gamma_astro\", \"Phi_0\", \"amplitude\", \"mean_energy\", \"width\"]),\n",
    "        \"fancy_names\":np.array([\"Conv. scaling\", r\"$\\gamma_{\\rm astro}$\", r\"$\\Phi_0 /({\\rm 10^{-18} GeV cm^2 s sr})$\",\n",
    "                  \"Amplitude\", r\"$\\log_{10}$(Mean energy/GeV)\", r\"$\\log_{10}$(Width/GeV)\"])\n",
    "    }\n",
    "}\n",
    "\n",
    "# some randomization of guessing parameters\n",
    "rs = np.random.RandomState(seed=667)\n",
    "for shape in shape_params:\n",
    "    shape_params[shape][\"guess\"] = np.copy(shape_params[shape][\"baseline\"]) \\\n",
    "                * rs.uniform(0.98, 1.02, size=len(shape_params[shape][\"baseline\"]))\n",
    "# alternative: give it the truth to supress minimizer errors\n",
    "#for shape in shape_params:\n",
    "#    shape_params[shape][\"guess\"] = deepcopy(shape_params[shape][\"baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(energy, events, labels, title, f, ax, **kwargs):\n",
    "    ls = kwargs.pop(\"ls\", [\"-\"] * len(events))\n",
    "    color = kwargs.pop(\"color\", [None] * len(events))\n",
    "    ylim = kwargs.pop(\"ylim\", (0.1, 3E4))\n",
    "    xlim = kwargs.pop(\"xlim\", (1.8, 9))\n",
    "    ylabel = kwargs.pop(\"ylabel\", r\"# events\")\n",
    "    xlabel = kwargs.pop(\"xlabel\", r\"$E_{\\mu \\, \\rm reco}$/GeV\")\n",
    "    \n",
    "    for i, (ev, lab) in enumerate(zip(events, labels)):\n",
    "        ax.plot(\n",
    "            energy, ev, drawstyle=\"steps-mid\", label=lab, \n",
    "            ls=ls[i],\n",
    "            color=color[i],\n",
    "        )\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    f.tight_layout()\n",
    "    return f, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot exemplary shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### true energy\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME    \n",
    "    events = [\n",
    "        np.sum(astro_flux(\n",
    "            \"double powerlaw\", aeff_factor, emids, E_NORM, smear_energy=False,\n",
    "            *shape_params[\"double powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\n",
    "            \"powerlaw\", aeff_factor, emids, E_NORM, smear_energy=False,\n",
    "            *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals, smear_energy=False), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Double Powerlaw\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \"-\"]\n",
    "    color = [None, \"k\", \"gray\"]\n",
    "    f, ax = plot_spectrum(\n",
    "        emids, events, plot_labels, title=ident, f=f, ax=ax,\n",
    "        ls=ls, color=color, xlabel=r\"$E_{\\nu}$/GeV\", xlim=(1E2, 1E9))\n",
    "    ax.set_xscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "## reco energy\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME    \n",
    "    events = [\n",
    "        np.sum(astro_flux(\"double powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"double powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Double Powerlaw\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \"-\"]\n",
    "    color = [None, \"k\", \"gray\"]\n",
    "    plot_spectrum(eri, events, plot_labels, title=ident, f=f, ax=ax, ls=ls, color=color)\n",
    "plt.show()\n",
    "\n",
    "#### to be moved to separate script\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    ident = label.split(\" \")[-1]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME\n",
    "    events = [\n",
    "        np.sum(astro_flux(\"powerlaw with dip\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw with dip\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw with bump\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw with bump\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Dip\", \"Bump\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \":\", \"-\"]\n",
    "    color = [None, None, \"k\", \"gray\"]\n",
    "    plot_spectrum(eri, events, plot_labels, title=ident, f=f, ax=ax, ls=ls, color=color)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME    \n",
    "    events = [\n",
    "        np.sum(astro_flux(\"powerlaw cutoff\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw with cutoff\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Powerlaw with cutoff\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \"-\"]\n",
    "    color = [None, \"k\", \"gray\"]\n",
    "    plot_spectrum(eri, events, plot_labels, title=ident, f=f, ax=ax, ls=ls, color=color)\n",
    "plt.show()\n",
    "\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME    \n",
    "    events = [\n",
    "        np.sum(astro_flux(\"log-parabola\", aeff_factor, emids, E_NORM, *shape_params[\"log-parabola\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Log-Parabola\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \"-\"]\n",
    "    color = [None, \"k\", \"gray\"]\n",
    "    plot_spectrum(eri, events, plot_labels, title=ident, f=f, ax=ax, ls=ls, color=color)\n",
    "plt.show()\n",
    "\n",
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "f, axes = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i, ident in enumerate(idents):\n",
    "    ax = axes[i]\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident]) * LIVETIME    \n",
    "    events = [\n",
    "        np.sum(astro_flux(\"powerlaw with sigmoid\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw with sigmoid\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *shape_params[\"powerlaw\"][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Powerlaw with Sigmoid\", \"Powerlaw\", \"Conv.\"]\n",
    "    ls = [\"-\", \"--\", \"-\"]\n",
    "    color = [None, \"k\", \"gray\"]\n",
    "    plot_spectrum(eri, events, plot_labels, title=ident, f=f, ax=ax, ls=ls, color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define likelihood and test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### to be moved to separate script\n",
    "def spectral_ts_func(x, aeff_factor, emids, enorm, k_i, shape, verbose=False, **kwargs):\n",
    "    \"\"\"First parameter is always conv scaling, rest is defined in astro_flux()\"\"\"\n",
    "    # free parameters\n",
    "    _conv_scaling = x[0]\n",
    "    background_spl = kwargs.pop(\"background_spl\", spl_vals)\n",
    "    # astro events with single powerlaw\n",
    "    # this is already smeared in energy\n",
    "    astro_ev = astro_flux(shape, aeff_factor, emids, enorm, *x[1:])\n",
    "    if verbose:\n",
    "        print(x)\n",
    "        print(*x[1:])\n",
    "        print(np.sum(astro_ev))\n",
    "    # atm events based on MCEQ with scaling factor\n",
    "    atm_ev = atmo_background(aeff_factor, background_spl * _conv_scaling)\n",
    "    # this defines the LLH function with free parameters\n",
    "    all_mu_i = astro_ev + atm_ev\n",
    "    return -2 * np.sum(\n",
    "        np.where(\n",
    "            all_mu_i > 0,\n",
    "            k_i * np.log(all_mu_i) - all_mu_i \\\n",
    "                - 0.5 * np.log(2*np.pi*k_i) + k_i - k_i * np.log(k_i),\n",
    "            0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### to be moved to separate script\n",
    "def local_ts_func(x, fixed_params, free_positions, fixed_params_positions, *args):\n",
    "    r\"\"\" Reduce full likelihood function with fixed parameters, i.e. reduce to\n",
    "    a 'local' likelihood function. Free and fixed parameters are combined in one\n",
    "    array to be piped through to 'spectral_ts_func'.\n",
    "    -----------------------------------------------------------------------\n",
    "    \n",
    "    x: free parameters, piped through to 'spectral_ts_func'\n",
    "    fixed_params: value of fixed parameters\n",
    "    free_positions: array indices of free parameters\n",
    "    fixed_params_positions: array indices of fixed parameters\n",
    "    *args: piped through to 'spectral_ts_func'\n",
    "    \n",
    "    returns spectral_ts_func(free_and_fixed_parameters, *args)\n",
    "    \"\"\"\n",
    "    all_x = np.zeros(len(x) + len(fixed_params))\n",
    "    for i, pos in enumerate(fixed_params_positions):\n",
    "        all_x[pos] = fixed_params[i]\n",
    "    for i, pos in enumerate(free_positions):\n",
    "        all_x[pos] = x[i]\n",
    "    return spectral_ts_func(all_x, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asimov_data(aeff_factor, shape_key, verbose=False, **kwargs):\n",
    "    shp_params = kwargs.pop(\"shp_params\", np.copy(shape_params[shape_key][\"baseline\"]))\n",
    "    background_spl = kwargs.pop(\"background_spl\", spl_vals)\n",
    "    # calculate asimov 'data' = expectation of perfect experiment\n",
    "    astro_ev = astro_flux(shape_key, aeff_factor, emids, E_NORM, *shp_params[1:])\n",
    "    if verbose:\n",
    "        print(\"baseline astro ev\", np.sum(astro_ev))\n",
    "    atm_ev = atmo_background(aeff_factor, background_spl * shp_params[0])\n",
    "    # asimov = expectation of perfect experiment\n",
    "    return astro_ev + atm_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all shapes and make a spectral fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "verbose = True\n",
    "fit_results = {}\n",
    "for shape in shape_params:\n",
    "    print(shape)\n",
    "    fit_results[shape] = {}\n",
    "    for li, ident in enumerate(idents):\n",
    "        if verbose: print(ident)\n",
    "        aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "        if \"Plenum\" in ident:\n",
    "            aeff_factor += aeff_eval_e_sd(aeff_2d[\"IceCube\"], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "        # asimov = expectation of perfect experiment\n",
    "        k_i = asimov_data(aeff_factor, shape, verbose=False)\n",
    "\n",
    "        # global min\n",
    "        out = fmin_l_bfgs_b(\n",
    "            spectral_ts_func,\n",
    "            x0=shape_params[shape][\"guess\"],\n",
    "            bounds=shape_params[shape][\"bounds\"],\n",
    "            approx_grad=True,\n",
    "            args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "        )\n",
    "        print(\"shape fit:\", out[0])\n",
    "        fit_results[shape][ident] = out\n",
    "        if out[2]['warnflag'] != 0:\n",
    "            print(\"WARNING!!\")\n",
    "            \n",
    "        # check that the TS at the fit minimum is close to the TS of the baseline params\n",
    "        baseline_ts = spectral_ts_func(\n",
    "            shape_params[shape][\"baseline\"],\n",
    "            aeff_factor, emids, E_NORM, k_i, shape\n",
    "        )\n",
    "        baseline_ts_check = np.isclose(\n",
    "            out[1], baseline_ts, rtol=1E-3\n",
    "        )\n",
    "        print(\"TS asimov check:\", \"OK\" if baseline_ts_check else \"not OK :(\")\n",
    "        print(\"fit: \", out[1], \", reference:\", baseline_ts)\n",
    "        # best fit powerlaw as null hypothesis     \n",
    "        out_pl = fmin_l_bfgs_b(\n",
    "            spectral_ts_func,\n",
    "            x0=shape_params[\"powerlaw\"][\"guess\"],            \n",
    "            bounds=shape_params[\"powerlaw\"][\"bounds\"],\n",
    "            approx_grad=True,\n",
    "            args=(aeff_factor, emids, E_NORM, k_i, \"powerlaw\")\n",
    "        )\n",
    "        ## be aware: this doesn't tell you whether or not the fit worked\n",
    "        ## a 2D scan can confirm (see below)\n",
    "        print(\"pl fit:\", out_pl[0])        \n",
    "        pval = chi2.sf(out_pl[1] - out[1], 1)\n",
    "        significance = erfinv(1 - pval) * np.sqrt(2)\n",
    "        print(\"P-VALUE:\", pval, \", SIGNIFICANCE:\", significance)\n",
    "        if False: #verbose:\n",
    "            print(\"asimov baseline param: \", shape_params[shape][\"baseline\"])\n",
    "            print(\"bf param:\", fit_results[shape][ident][0])\n",
    "            print(\"guess param: \", shape_params[shape][\"guess\"])\n",
    "            print(\"diff (truth vs fit):\", shape_params[shape][\"baseline\"]/ fit_results[shape][ident][0] -1)\n",
    "            print(\"* *\" * 30)\n",
    "    print(\"- -\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for shape in shape_params:\n",
    "    print(shape)\n",
    "    f, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "    for li, ident in enumerate(idents):\n",
    "        ax = axes[li]\n",
    "        aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "        events = [\n",
    "            np.sum(atmo_background(aeff_factor, spl_vals * shape_params[shape][\"baseline\"][0]), axis=0),\n",
    "            np.sum(atmo_background(aeff_factor, spl_vals * fit_results[shape][ident][0][0]), axis=0),\n",
    "            np.sum(astro_flux(shape, aeff_factor, emids, E_NORM, *shape_params[shape][\"baseline\"][1:]), axis=0),\n",
    "            np.sum(astro_flux(shape, aeff_factor, emids, E_NORM, *fit_results[shape][ident][0][1:]), axis=0)\n",
    "        ]\n",
    "        plot_labels = [\"Conv., Truth\", \"Conv., Fit\", shape + \", Truth\", shape + \", Fit\"]\n",
    "        ls = [\"-\", \":\", \"-\", \":\"]\n",
    "        color = [\"gray\", \"darkgray\", None, \"k\"]\n",
    "        f, ax = plot_spectrum(eri, events, plot_labels, title=ident + \", \" + shape, f=f, ax=ax, ls=ls, color=color)        \n",
    "        ax.legend(fontsize=\"xx-small\", loc=1)\n",
    "        f.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D scan powerlaw\n",
    "Calculate expected parameter uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "num = 100\n",
    "gamma_astro_scaling = np.linspace(1.9, 2.7, num=num+1)\n",
    "astro_scaling = np.linspace(0.4, 2.6, num=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_SPL = {\n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"gamma\": {},\n",
    "    \"phi_astro\": {}\n",
    "}\n",
    "local_SPL_gamma_scan = {    \n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"phi_astro\": {}\n",
    "}\n",
    "local_SPL_phi_scan = {    \n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"gamma\": {}\n",
    "}\n",
    "shape = \"powerlaw\"\n",
    "for ident in idents:\n",
    "    print(ident)\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    if \"Plenum\" in ident:\n",
    "        aeff_factor += aeff_eval_e_sd(aeff_2d[\"IceCube\"], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    # asimov = expectation of perfect experiment\n",
    "    k_i = asimov_data(\n",
    "        aeff_factor, \n",
    "        shape, \n",
    "        verbose=verbose)\n",
    "\n",
    "    # global min\n",
    "    out = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[shape][\"guess\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "    )\n",
    "    if out[2]['warnflag'] != 0:\n",
    "        print(\"WARNING!!\")\n",
    "    print(\"asimov param: \", shape_params[shape][\"baseline\"])\n",
    "    print(\"bf param:\", out[0])\n",
    "    \n",
    "    bf_SPL[\"ts\"][ident] = out[1]\n",
    "    bf_SPL[\"conv\"][ident] = out[0][0]\n",
    "    bf_SPL[\"gamma\"][ident] = out[0][1]\n",
    "    bf_SPL[\"phi_astro\"][ident] = out[0][2]\n",
    "    \n",
    "    local_SPL_gamma_scan[\"ts\"][ident] = np.zeros_like(gamma_astro_scaling)\n",
    "    local_SPL_gamma_scan[\"conv\"][ident] = np.zeros_like(gamma_astro_scaling)\n",
    "    local_SPL_gamma_scan[\"phi_astro\"][ident] = np.zeros_like(gamma_astro_scaling)\n",
    "    print(\"starting local fits...\")\n",
    "    for j, gas in enumerate(gamma_astro_scaling):\n",
    "        # local min with fixed phi_astro\n",
    "        local_out = fmin_l_bfgs_b(\n",
    "            local_ts_func,\n",
    "            x0=[1.0, 1.0],\n",
    "            approx_grad=True,\n",
    "            args=([gas], (0, 2), (1, ), aeff_factor, emids, E_NORM, k_i, shape)\n",
    "        )\n",
    "        local_SPL_gamma_scan[\"conv\"][ident][j], local_SPL_gamma_scan[\"phi_astro\"][ident][j]= local_out[0]\n",
    "        local_SPL_gamma_scan[\"ts\"][ident][j] = local_out[1]\n",
    "        \n",
    "    local_SPL_phi_scan[\"ts\"][ident] = np.zeros_like(astro_scaling)\n",
    "    local_SPL_phi_scan[\"conv\"][ident] = np.zeros_like(astro_scaling)\n",
    "    local_SPL_phi_scan[\"gamma\"][ident] = np.zeros_like(astro_scaling)\n",
    "    print(\"starting local fits...\")\n",
    "    for j, aas in enumerate(astro_scaling):\n",
    "        # local min with fixed phi_astro\n",
    "        local_out = fmin_l_bfgs_b(\n",
    "            local_ts_func,\n",
    "            x0=[1.0, 2.2],\n",
    "            approx_grad=True,\n",
    "            args=([aas], (0, 1), (2, ), aeff_factor, emids, E_NORM, k_i, shape)\n",
    "        )\n",
    "        local_SPL_phi_scan[\"conv\"][ident][j], local_SPL_phi_scan[\"gamma\"][ident][j]= local_out[0]\n",
    "        local_SPL_phi_scan[\"ts\"][ident][j] = local_out[1]\n",
    "    print(\"done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ident in idents:\n",
    "    plt.plot(gamma_astro_scaling, local_SPL_gamma_scan[\"ts\"][ident] - bf_SPL[\"ts\"][ident], label=ident)\n",
    "plt.ylim(0, 2)\n",
    "plt.xlim(2.1, 2.4)\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel(r\"$\\gamma_{\\rm astro}$\")\n",
    "plt.ylabel(r\"-2$\\Delta$LLH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ident in idents:\n",
    "    plt.plot(astro_scaling, local_SPL_phi_scan[\"ts\"][ident] - bf_SPL[\"ts\"][ident], label=ident)\n",
    "plt.ylim(0, 2)\n",
    "plt.xlim(1, 2)\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(r\"$\\Phi_{\\rm astro}$\")\n",
    "plt.ylabel(r\"-2$\\Delta$LLH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D scan powerlaw\n",
    "Show that we can roughly reproduce the diffuse results from ICRC2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "num = 50\n",
    "gamma_astro_scaling = np.linspace(1.9, 2.7, num=num+1)\n",
    "astro_scaling = np.linspace(0.4, 2.6, num=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_SPL = {\n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"gamma\": {},\n",
    "    \"phi_astro\": {}\n",
    "}\n",
    "local_SPL = {    \n",
    "    \"ts\": {},\n",
    "    \"conv\": {}\n",
    "}\n",
    "\n",
    "shape = \"powerlaw\"\n",
    "for ident in idents:\n",
    "    print(ident)\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    if \"Plenum\" in ident:\n",
    "        aeff_factor += aeff_eval_e_sd(aeff_2d[\"IceCube\"], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    # asimov = expectation of perfect experiment\n",
    "    k_i = asimov_data(\n",
    "        aeff_factor, \n",
    "        shape, \n",
    "        verbose=verbose)\n",
    "\n",
    "    # global min\n",
    "    out = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[shape][\"guess\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "    )\n",
    "    if out[2]['warnflag'] != 0:\n",
    "        print(\"WARNING!!\")\n",
    "    print(\"asimov param: \", shape_params[shape][\"baseline\"])\n",
    "    print(\"bf param:\", out[0])\n",
    "    \n",
    "    bf_SPL[\"ts\"][ident] = out[1]\n",
    "    bf_SPL[\"conv\"][ident] = out[0][0]\n",
    "    bf_SPL[\"gamma\"][ident] = out[0][1]\n",
    "    bf_SPL[\"phi_astro\"][ident] = out[0][2]\n",
    "    \n",
    "    local_SPL[\"ts\"][ident] = np.zeros((num, num+1))\n",
    "    local_SPL[\"conv\"][ident] = np.zeros((num, num+1))\n",
    "    print(\"starting local fits...\")\n",
    "    for i, asc in enumerate(astro_scaling):\n",
    "        for j, gas in enumerate(gamma_astro_scaling):\n",
    "            # local min with fixed phi_astro\n",
    "            local_out = fmin_l_bfgs_b(\n",
    "                local_ts_func,\n",
    "                x0=[1.1],\n",
    "                approx_grad=True,\n",
    "                args=([gas, asc], (0, ), (1, 2), aeff_factor, emids, E_NORM, k_i, shape)\n",
    "            )\n",
    "            local_SPL[\"conv\"][ident][i][j], = local_out[0]\n",
    "            local_SPL[\"ts\"][ident][i][j] = local_out[1]\n",
    "    print(\"done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contour comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison data of official 9.5yr fit by Jöran Stettner (IceCube ICRC2019)\n",
    "joeran = np.genfromtxt(\"../resources/10yr_diffuse_ICRC2019.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only 95% contours\n",
    "contour_formats = {\n",
    "    \"IceCube\": {\"colors\": [poles[\"IceCube\"][\"color\"]], \"linestyles\": \"--\"},\n",
    "    \"Plenum-1\": {\"colors\": [poles[\"Plenum-1\"][\"color\"]], \"linestyles\": poles[\"Plenum-1\"][\"ls\"]},\n",
    "    \"Plenum-2\": {\"colors\": [poles[\"Plenum-2\"][\"color\"]], \"linestyles\": poles[\"Plenum-2\"][\"ls\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "num = 50\n",
    "gamma_astro_scaling = np.linspace(1.9, 2.7, num=num+1)\n",
    "astro_scaling = np.linspace(0.4, 2.6, num=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "## correctly sort extracted contour from joeran's latest diffuse fit\n",
    "ref_color = \"gray\"\n",
    "idx = np.argsort(np.arctan2(joeran[:,1] - np.mean(joeran[:,1]), joeran[:,0] - np.mean(joeran[:,0])))\n",
    "xx = joeran[:,0][idx]\n",
    "xx = np.concatenate([[xx[-1]], xx])\n",
    "yy = joeran[:,1][idx]\n",
    "yy = np.concatenate([[yy[-1]], yy])\n",
    "ax.plot(xx, yy, color=ref_color, ls=\"-\", lw=5, alpha=0.5)\n",
    "\n",
    "# draw contour levels\n",
    "cvals = [0.05]\n",
    "lbs = [\"95%\"]\n",
    "levels = chi2.isf(cvals, 2)\n",
    "for ident in idents:\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        astro_scaling,\n",
    "        local_SPL[\"ts\"][ident] - bf_SPL[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        lw=3, **contour_formats[ident]\n",
    "    )\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=12)\n",
    "# best fit\n",
    "ax.scatter(\n",
    "    bf_SPL[\"gamma\"][ident], bf_SPL[\"phi_astro\"][ident], \n",
    "    marker=\"*\", s=200, color=\"k\", edgecolor=ref_color)\n",
    "lines = [\n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"IceCube\"][\"colors\"][0], \n",
    "        ls=contour_formats[\"IceCube\"][\"linestyles\"],\n",
    "        lw=3, label=\"IceCube\"),\n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"Plenum-1\"][\"colors\"][0], \n",
    "        ls=contour_formats[\"Plenum-1\"][\"linestyles\"],\n",
    "        lw=3, label=r\"IceCube+PLE$\\nu$M-1\"),    \n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"Plenum-2\"][\"colors\"][0], \n",
    "        ls=contour_formats[\"Plenum-2\"][\"linestyles\"],\n",
    "        lw=3, label=r\"IceCube+PLE$\\nu$M-2\"),\n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), color=ref_color, ls=\"-\", \n",
    "        lw=3, markersize=18, alpha=0.8, \n",
    "        marker=\"*\", mfc='k', mec=ref_color,\n",
    "        label=r\"9.5yr IceCube $\\nu_\\mu$, 95% CL.\"\n",
    "    )\n",
    "]\n",
    "ax.set_ylim(0.1, 2.5)\n",
    "ax.set_xlim(1.9, 2.6)\n",
    "ax.legend(handles=lines, loc=4, ncol=2, fontsize=\"x-small\")\n",
    "ax.set_ylabel(r\"$\\Phi_0 \\cdot 10^{18} / {\\rm GeV\\, cm^2\\, s\\, sr}$\")\n",
    "ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "flux_str = r\"$\\frac{{\\rm d}\\Phi_{\\rm astro}^{\\nu_\\mu + \\bar{\\nu}_\\mu}}{{\\rm d}E}\"\n",
    "flux_str += r\"= \\Phi_0 \\left( \\frac{E}{\\rm 100\\,TeV} \\right)^{-\\gamma}$\"\n",
    "ax.text(\n",
    "    1.92, 2.2, flux_str, fontsize=\"medium\",\n",
    "    bbox=dict(boxstyle='round', facecolor=\"w\", edgecolor=\"gray\", alpha=0.8)\n",
    ")\n",
    "ax.set_title(\"Diffuse flux: 10yr livetime\")\n",
    "f.tight_layout()\n",
    "f.savefig(f\"../plots/2D_scan_diffuse_spl_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full scan comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_color = \"tab:orange\"\n",
    "for ident in idents:\n",
    "    print(ident)\n",
    "    ### plotting ###\n",
    "    f, axes = plt.subplots(ncols=2, figsize=(18,6))\n",
    "    ax = axes[0]\n",
    "    # draw llh grid for gamma and astro flux\n",
    "    im = ax.pcolormesh(\n",
    "        gamma_astro_scaling,\n",
    "        astro_scaling,\n",
    "        local_SPL[\"ts\"][ident] - bf_SPL[\"ts\"][ident],\n",
    "        vmax=15 # 6 is approx. the 95% quantile of a 2D LLH scan\n",
    "    )\n",
    "    cb = plt.colorbar(im, ax=ax)\n",
    "    # draw contour levels\n",
    "    cvals = np.array([0.32, 0.05, 0.01])\n",
    "    levels = chi2.isf(cvals, 2)\n",
    "    lbs = np.array([\"68%\", \"95%\", \"99%\"])\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        astro_scaling,\n",
    "        local_SPL[\"ts\"][ident] - bf_SPL[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        colors=[\"w\", \"0.8\", \"k\"]\n",
    "    )\n",
    "    ax.scatter(bf_SPL[\"gamma\"][ident], bf_SPL[\"phi_astro\"][ident], marker=\"*\", s=50)\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=16)\n",
    "    # correctly sort extracted contour from joeran's latest diffuse fit\n",
    "    idx = np.argsort(np.arctan2(joeran[:,1] - np.mean(joeran[:,1]), joeran[:,0] - np.mean(joeran[:,0])))\n",
    "    xx = joeran[:,0][idx]\n",
    "    xx = np.concatenate([[xx[-1]], xx])\n",
    "    yy = joeran[:,1][idx]\n",
    "    yy = np.concatenate([[yy[-1]], yy])\n",
    "    ax.plot(xx, yy, color=ref_color, label=r\"9.5yr IC diffuse $\\nu_\\mu$, 95% CL\")\n",
    "    ax.legend(loc=2)\n",
    "    ax.set_ylabel(r\"$\\Phi_{\\rm astro} (100\\,{\\rm TeV})\\cdot 10^{18} / {\\rm GeV\\, cm^2\\, s\\, sr}$\")\n",
    "    ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "    cb.set_label(r\"$-2 \\Delta$ LLH\")\n",
    "    ax.set_title(ident)\n",
    "\n",
    "\n",
    "    # in addition, check the nuisance parameter of conventional flux\n",
    "    ax = axes[1]\n",
    "    im = ax.pcolormesh(\n",
    "        gamma_astro_scaling,\n",
    "        astro_scaling,\n",
    "        local_SPL[\"conv\"][ident],\n",
    "    )\n",
    "    ax.set_ylabel(r\"$\\Phi_{\\rm astro} (100\\,{\\rm TeV})\\cdot 10^{18} / {\\rm GeV\\, cm^2\\, s\\, sr}$\")\n",
    "    ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "    cb = plt.colorbar(im, ax=ax)\n",
    "    cb.set_label(r\"Atmospheric flux scaling\")\n",
    "\n",
    "    f.tight_layout()\n",
    "    f.savefig(f\"../plots/2D_scan_diffuse_spl_{ident}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D scan with cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "verbose = False\n",
    "num = 50\n",
    "cutoff = np.linspace(5.5, 6.5, num=num)\n",
    "\n",
    "num1 = 30\n",
    "gamma_astro_scaling = np.linspace(1.9, 2.7, num=num1+1)\n",
    "astro_scaling = np.linspace(0.4, 2.6, num=num1)\n",
    "\n",
    "ts_mins_pl = {}\n",
    "gamma_mins_pl = {}\n",
    "phi_astro_mins_pl = {}\n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "f1, axes1 = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for li, ident in enumerate(idents):\n",
    "    print(ident)\n",
    "    shape = \"powerlaw with cutoff\"\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    # asimov = expectation of perfect experiment\n",
    "    k_i = asimov_data(aeff_factor, shape, verbose=verbose)  \n",
    "\n",
    "    # global min\n",
    "    out = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[shape][\"guess\"],\n",
    "        bounds=shape_params[shape][\"bounds\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "    )\n",
    "    if out[2]['warnflag'] != 0:\n",
    "        print(\"WARNING!!\")\n",
    "    if verbose:\n",
    "        print(\"asimov param: \", *shape_params[shape][\"baseline\"][1:])\n",
    "        print(\"guess param: \", *shape_params[shape][\"guess\"])\n",
    "        print(\"bf param:\", out[0])\n",
    "        print(\"TS:\", out[1])\n",
    "        print(\"* *\"*20)\n",
    "\n",
    "    local_ts_min = np.zeros(num)\n",
    "    local_param_min = {\n",
    "        \"gamma\": np.zeros(num),\n",
    "        \"conv\": np.zeros(num),\n",
    "        \"asc\": np.zeros(num)\n",
    "    }\n",
    "    for i, cc in enumerate(cutoff):\n",
    "        # local min with fixed phi_astro\n",
    "        local_out = fmin_l_bfgs_b(\n",
    "            local_ts_func,\n",
    "            x0=shape_params[shape][\"guess\"][:3],\n",
    "            bounds=shape_params[shape][\"bounds\"][:3],\n",
    "            approx_grad=True,\n",
    "            args=([cc], (0, 1, 2), (3,), aeff_factor, emids, E_NORM, k_i, shape)\n",
    "        )\n",
    "        local_param_min[\"conv\"][i], local_param_min[\"gamma\"][i], local_param_min[\"asc\"][i] = local_out[0]\n",
    "        local_ts_min[i] = local_out[1]\n",
    "    \n",
    "    # best fit powerlaw as null hypothesis     \n",
    "    out_pl = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[\"powerlaw\"][\"guess\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, \"powerlaw\")\n",
    "    )\n",
    "    gamma_mins_pl[ident] = out_pl[0][1]\n",
    "    phi_astro_mins_pl[ident] = out_pl[0][2]\n",
    "    ts_mins_pl[ident] = out_pl[1]\n",
    "    \n",
    "    ### verify with 2D scan that the result is the correct minimum\n",
    "    local_ts_min_pl = np.zeros((num1, num1+1))\n",
    "    local_conv_min_pl = np.zeros((num1, num1+1))\n",
    "    print(\"starting local fits...\")\n",
    "    # scan\n",
    "    for i, asc in enumerate(astro_scaling):\n",
    "        for j, gas in enumerate(gamma_astro_scaling):\n",
    "            # local min with fixed phi_astro\n",
    "            local_out = fmin_l_bfgs_b(\n",
    "                local_ts_func,\n",
    "                x0=[1.1],\n",
    "                approx_grad=True,\n",
    "                args=([gas, asc], (0, ), (1, 2), aeff_factor, emids, E_NORM, k_i, \"powerlaw\")\n",
    "            )\n",
    "            local_conv_min_pl[i][j], = local_out[0]\n",
    "            local_ts_min_pl[i][j] = local_out[1]    \n",
    "    print(\"alternative: powerlaw fit (conv, gamma, phi_astro)\", out_pl[0])\n",
    "    iag, ias = np.unravel_index(local_ts_min_pl.argmin(), local_ts_min_pl.shape)\n",
    "    print(\"params at min verified with scan: (conv, gamma, phi_astro)\", \n",
    "          local_conv_min_pl.flatten()[local_ts_min_pl.argmin()], gamma_astro_scaling[iag], astro_scaling[ias])\n",
    "    print(\"min TS:\", out_pl[1], \"verified with scan:\", np.min(local_ts_min_pl))\n",
    "    print(\"Raw TS vals of powerlaw vs cutoff:\",out_pl[1], out[1])\n",
    "    pval = chi2.sf(out_pl[1] - out[1], 1)\n",
    "    significance = erfinv(1 - pval) * np.sqrt(2)\n",
    "    print(\"P-VALUE:\", pval, \", SIGNIFICANCE:\", significance)\n",
    "\n",
    "    # plot best-fit event distributions and truth\n",
    "    \n",
    "    ax = axes1[li]\n",
    "    events = [\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals * shape_params[shape][\"baseline\"][0]), axis=0),\n",
    "        np.sum(atmo_background(aeff_factor, spl_vals * out[0][0]), axis=0),\n",
    "        np.sum(astro_flux(shape, aeff_factor, emids, E_NORM, *shape_params[shape][\"baseline\"][1:]), axis=0),\n",
    "        np.sum(astro_flux(shape, aeff_factor, emids, E_NORM, *out[0][1:]), axis=0),\n",
    "        np.sum(astro_flux(\"powerlaw\", aeff_factor, emids, E_NORM, *out_pl[0][1:]), axis=0)\n",
    "    ]\n",
    "    plot_labels = [\"Conv., Truth\", \"Conv., Fit\", shape + \", Truth\", shape + \", Fit\", \"Single powerlaw, Fit\"]\n",
    "    ls = [\"-\", \":\", \"-\", \"--\", \":\"]\n",
    "    color = [\"gray\", None, \"k\", None, None]\n",
    "    f, ax = plot_spectrum(eri, events, plot_labels, title=shape, f=f, ax=ax, ls=ls, color=color)        \n",
    "    ax.legend(fontsize=\"xx-small\", loc=1, ncol=2)\n",
    "    f.tight_layout()\n",
    "\n",
    "    ## some plots for checking that the scans were ok\n",
    "    ax = axes[0][0]\n",
    "    ax.plot(cutoff, local_ts_min- out[1], label=ident)\n",
    "    ax.set_ylabel(r\"-2 $\\Delta$ LLH\")\n",
    "    ax.set_xlabel(\"cutoff\")\n",
    "    ax.legend(loc=0)\n",
    "    ax.axvline(shape_params[shape][\"baseline\"][-1], color=\"k\", ls=\":\")\n",
    "    ax.axvline(out[0][-1])\n",
    "    ax.set_ylim(0, 4)\n",
    "    \n",
    "    ax = axes[0][1]\n",
    "    ax.set_ylabel(r\"$\\gamma$\")\n",
    "    ax.set_xlabel(\"cutoff\")\n",
    "    ax.plot(cutoff, local_param_min[\"gamma\"], label=ident)\n",
    "    ax.legend(loc=0)\n",
    "    ax.axvline(shape_params[shape][\"baseline\"][-1], color=\"k\", ls=\":\")\n",
    "    ax.axhline(shape_params[\"powerlaw with cutoff\"][\"baseline\"][1])\n",
    "    \n",
    "    ax = axes[1][0]\n",
    "    ax.set_ylabel(r\"conv scaling\")\n",
    "    ax.set_xlabel(\"cutoff\")\n",
    "    ax.plot(cutoff, local_param_min[\"conv\"], label=ident)\n",
    "    ax.legend(loc=0)\n",
    "    ax.axvline(shape_params[shape][\"baseline\"][-1], color=\"k\", ls=\":\")\n",
    "    ax.axhline(shape_params[\"powerlaw with cutoff\"][\"baseline\"][0])\n",
    "    \n",
    "    \n",
    "    ax = axes[1][1]\n",
    "    ax.set_ylabel(r\"asc scaling\")\n",
    "    ax.set_xlabel(\"cutoff\")\n",
    "    ax.plot(cutoff, local_param_min[\"asc\"], label=ident)\n",
    "    ax.legend(loc=0)\n",
    "    ax.axvline(shape_params[shape][\"baseline\"][-1], color=\"k\", ls=\":\")\n",
    "    ax.axhline(shape_params[\"powerlaw with cutoff\"][\"baseline\"][2])\n",
    "    axes1[li].legend(fontsize=\"xx-small\", loc=0)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D scans with cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(many_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idents = [\"IceCube\", \"Plenum-1\", \"Plenum-2\"]\n",
    "verbose = False\n",
    "num = 50\n",
    "cutoff = np.linspace(4.5, 8.5, num=num)\n",
    "gamma_astro_scaling = np.linspace(1.0, 2.9, num=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bf_PLC = {\n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"gamma\": {},\n",
    "    \"phi_astro\": {},\n",
    "    \"cutoff\": {}\n",
    "}\n",
    "local_mins_PLC = {    \n",
    "    \"ts\": {},\n",
    "    \"conv\": {},\n",
    "    \"phi_astro\": {}\n",
    "}\n",
    "shape = \"powerlaw with cutoff\"\n",
    "\n",
    "for li, ident in enumerate(idents):\n",
    "    print(ident)\n",
    "    aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "    # asimov = expectation of perfect experiment\n",
    "    k_i = asimov_data(aeff_factor, shape, verbose=verbose)  \n",
    "\n",
    "    # global min\n",
    "    out = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[shape][\"guess\"],\n",
    "        bounds=shape_params[shape][\"bounds\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "    )\n",
    "    bf_PLC[\"ts\"][ident] = out[1]\n",
    "    bf_PLC[\"conv\"][ident], bf_PLC[\"gamma\"][ident], bf_PLC[\"phi_astro\"][ident], bf_PLC[\"cutoff\"][ident] = out[0]\n",
    "    if out[2]['warnflag'] != 0:\n",
    "        print(\"WARNING!! Something weird happened with the fit\")\n",
    "\n",
    "    local_mins_PLC[\"ts\"][ident] = np.zeros((len(cutoff), len(gamma_astro_scaling)))\n",
    "    local_mins_PLC[\"conv\"][ident] = np.zeros((len(cutoff), len(gamma_astro_scaling)))\n",
    "    local_mins_PLC[\"phi_astro\"][ident] = np.zeros((len(cutoff), len(gamma_astro_scaling)))\n",
    "    print(\"starting local fits...\")\n",
    "    # scan\n",
    "    nwarn = 0\n",
    "    for i, csc in enumerate(cutoff):\n",
    "        for j, gas in enumerate(gamma_astro_scaling):\n",
    "            # local min with fixed phi_astro\n",
    "            local_out = fmin_l_bfgs_b(\n",
    "                local_ts_func,\n",
    "                x0=shape_params[shape][\"baseline\"][[0, 2]],\n",
    "                bounds=shape_params[shape][\"bounds\"][[0, 2]]*((1, 1), (0.3, 3)), # losen up bounds a bit here for astro\n",
    "                approx_grad=True,\n",
    "                args=([gas, csc], (0, 2), (1, 3), aeff_factor, emids, E_NORM, k_i, shape),\n",
    "                maxls=35\n",
    "            )\n",
    "            if local_out[2]['warnflag'] == 0:\n",
    "                local_mins_PLC[\"conv\"][ident][i][j], local_mins_PLC[\"phi_astro\"][ident][i][j] = local_out[0]\n",
    "                local_mins_PLC[\"ts\"][ident][i][j] = local_out[1]\n",
    "            else:\n",
    "                strng = \"WARNING!! Something weird happened with the fit\"\n",
    "                strng += \"\\nParameters: cutoff={}, gamma={}\".format(csc, gas)\n",
    "                strng += \"\\n Fit Output:\" + str(local_out)\n",
    "                #print(strng)\n",
    "                local_mins_PLC[\"conv\"][ident][i][j] = np.nan\n",
    "                local_mins_PLC[\"phi_astro\"][ident][i][j] = np.nan\n",
    "                local_mins_PLC[\"ts\"][ident][i][j] = np.nan\n",
    "                nwarn += 1\n",
    "    print(\"Number of warnings:\", nwarn)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "cvals = [0.05]\n",
    "lbs = [\"95%\"]\n",
    "levels = chi2.isf(cvals, 2)\n",
    "for ident in idents:\n",
    "    # draw contour levels\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"ts\"][ident] - bf_PLC[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        lw=3, **contour_formats[ident]\n",
    "    )\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=12)\n",
    "    \n",
    "ax.scatter(bf_PLC[\"gamma\"][ident], bf_PLC[\"cutoff\"][ident], marker=\"*\", s=200, color=\"k\")\n",
    "handles, _ = ax.get_legend_handles_labels()\n",
    "handles.extend([\n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"IceCube\"][\"colors\"][0], ls=contour_formats[\"IceCube\"][\"linestyles\"], lw=3, label=\"IceCube\"),\n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"Plenum-1\"][\"colors\"][0], ls=contour_formats[\"Plenum-1\"][\"linestyles\"], lw=3, label=r\"IceCube+PLE$\\nu$M-1\"),    \n",
    "    matplotlib.lines.Line2D(\n",
    "        range(1), range(1), \n",
    "        color=contour_formats[\"Plenum-2\"][\"colors\"][0], ls=contour_formats[\"Plenum-2\"][\"linestyles\"], lw=3, label=r\"IceCube+PLE$\\nu$M-2\")\n",
    "])\n",
    "ax.legend(handles=handles, loc=4, ncol=2, fontsize=\"small\")\n",
    "ax.set_ylim(4.0, 8)\n",
    "flux_str = r\"$\\frac{{\\rm d}\\Phi_{\\rm astro}^{\\nu_\\mu + \\bar{\\nu}_\\mu}}{{\\rm d}E}\"\n",
    "flux_str += r\"= \\Phi_0 \\left( \\frac{E}{\\rm 100\\,TeV} \\right)^{-\\gamma}\"\n",
    "flux_str += r\" \\cdot \\exp \\left( \\frac{E}{E_{\\rm cut}}\\right)$\"\n",
    "ax.text(\n",
    "    1.05, 7.5, flux_str, fontsize=\"medium\",\n",
    "    bbox=dict(boxstyle='round', facecolor=\"w\", edgecolor=\"gray\", alpha=0.8)\n",
    ")\n",
    "ax.set_ylabel(r\"$\\log_{10}(E_{\\rm cut} / {\\rm GeV})$\")\n",
    "ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "ax.set_title(\"Diffuse flux with cutoff: 10yr livetime\")\n",
    "f.tight_layout()\n",
    "f.savefig(f\"../plots/2D_scan_diffuse_pl-cut_comparison_gamma-cut.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ident in idents:\n",
    "    print(ident)\n",
    "    ### plotting ###\n",
    "    f, ax = plt.subplots(figsize=(9,6))\n",
    "    # draw llh grid for gamma and astro flux\n",
    "    im = ax.pcolormesh(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"ts\"][ident] - bf_PLC[\"ts\"][ident],\n",
    "        vmin=0,\n",
    "        vmax=20\n",
    "    )\n",
    "    cb = plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    # draw contour levels\n",
    "    cvals = np.array([0.32, 0.05, 0.01])\n",
    "    levels = chi2.isf(cvals, 2)\n",
    "    lbs = np.array([\"68%\", \"95%\", \"99%\"])\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"ts\"][ident] - bf_PLC[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        colors=[\"w\", \"0.8\", \"0.2\"]\n",
    "    )\n",
    "    ax.scatter(bf_PLC[\"gamma\"][ident], bf_PLC[\"cutoff\"][ident], marker=\"*\", s=150, color=\"white\", edgecolor=\"gold\")\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=16)\n",
    "    \n",
    "    ax.set_ylabel(r\"log10(Cut-off energy / GeV)\")\n",
    "    ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "    cb.set_label(r\"$-2 \\Delta$ LLH\")\n",
    "    ax.set_title(ident)\n",
    "    f.tight_layout()\n",
    "    f.savefig(f\"../plots/2D_scan_diffuse_pl-cut_{ident}.pdf\")\n",
    "\n",
    "    f2, ax2 = plt.subplots(ncols=2, figsize=(18,6))\n",
    "    ## in addition, check the nuisance parameter of conventional flux\n",
    "    ax = ax2[0]\n",
    "    im = ax.pcolormesh(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"conv\"][ident],\n",
    "        #vmin=0.99,\n",
    "    )\n",
    "    \n",
    "    ## add contours as reference\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"ts\"][ident] - bf_PLC[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        colors=[\"w\", \"0.8\", \"0.2\"]\n",
    "    )\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=16)\n",
    "    ax.set_ylabel(r\"log10(Cut-off energy / GeV)\")\n",
    "    ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "    cb = plt.colorbar(im, ax=ax)\n",
    "    cb.set_label(r\"Atmospheric flux scaling\")\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax = ax2[1]\n",
    "    im2 = ax.pcolormesh(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"phi_astro\"][ident],\n",
    "        #vmin=0.99,\n",
    "    )\n",
    "    ## add contours as reference\n",
    "    sc = ax.contour(\n",
    "        gamma_astro_scaling,\n",
    "        cutoff,\n",
    "        local_mins_PLC[\"ts\"][ident] - bf_PLC[\"ts\"][ident],\n",
    "        levels=levels,\n",
    "        colors=[\"w\", \"0.8\", \"0.2\"]\n",
    "    )\n",
    "    fmt = {l: s for l,s in zip(sc.levels, lbs)}\n",
    "    ax.clabel(sc, levels, fmt=fmt, fontsize=16)\n",
    "    ax.set_ylabel(r\"log10(Cut-off energy / GeV)\")\n",
    "    ax.set_xlabel(r\"Spectral index $\\gamma$\")\n",
    "    cb = plt.colorbar(im2, ax=ax)\n",
    "    cb.set_label(r\"Astrophysical flux scaling\")\n",
    "    f2.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutoff significance versus time/detectors\n",
    "\n",
    "Some options:\n",
    "* 10yr IceCube\n",
    "* 20yr IceCube\n",
    "* 40yr IceCube\n",
    "* 10yr IceCube + K3N\n",
    "* 10yr IceCube + K3N + GVD\n",
    "* 10yr IceCube + K3N + GVD + PONE\n",
    "* 10yr IceCube +  2yr baseline Plenum (= IC + PONE + GVD + K3N)\n",
    "* 10yr IceCube +  5yr baseline Plenum (= IC + PONE + GVD + K3N)\n",
    "* 10yr IceCube + 10yr baseline Plenum (= IC + PONE + GVD + K3N)\n",
    "* 10yr IceCube +  2yr Plenum-2 (= GEN2 + PONE + GVD + K3N)\n",
    "* 10yr IceCube +  5yr Plenum-2 (= GEN2 + PONE + GVD + K3N)\n",
    "* 10yr IceCube + 10yr Plenum-2 (= GEN2 + PONE + GVD + K3N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# livetime relative to 10yrs\n",
    "detector_configurations = [\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"10y IC\"},\n",
    "    {\"IceCube\": 2.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"20y IC\"},\n",
    "    {\"IceCube\": 4.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"40y IC\"},\n",
    "    #{\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  1, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"10y IC + 10y K3\"},\n",
    "    #{\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  1, \"P-ONE\": 0, \"Baikal-GVD\": 1, \"identifier\": \"10y IC + 10y K3 + 10y BG\"},\n",
    "    #{\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0, \"KM3NeT\":  1, \"P-ONE\": 1, \"Baikal-GVD\": 1, \"identifier\": \"10y IC + 10y K3 + 10y BG + 10y PO\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0.2, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"10y IC + 2y PL-1\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 0.5, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"10y IC + 5y PL-1\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0, \"Plenum-1\": 1, \"KM3NeT\":  0, \"P-ONE\": 0, \"Baikal-GVD\": 0, \"identifier\": \"10y IC + 10y PL-1\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0.2, \"Plenum-1\": 0, \"KM3NeT\": 0.2, \"P-ONE\": 0.2, \"Baikal-GVD\": 0.2, \"identifier\": \"10y IC + 2y PL-2\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 0.5, \"Plenum-1\": 0, \"KM3NeT\": 0.5, \"P-ONE\": 0.5, \"Baikal-GVD\": 0.5, \"identifier\": \"10y IC + 5y PL-2\"},\n",
    "    {\"IceCube\": 1.0, \"Gen-2\": 1, \"Plenum-1\": 0, \"KM3NeT\": 1, \"P-ONE\": 1, \"Baikal-GVD\": 1, \"identifier\": \"10y IC + 10y PL-2\"},\n",
    "]\n",
    "detector_configurations = pd.DataFrame(detector_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pvals = []\n",
    "shape = \"powerlaw with cutoff\"\n",
    "\n",
    "for idx, series in detector_configurations.iterrows():\n",
    "    print(idx)\n",
    "    aeff_factor = np.zeros_like(aeff_2d[\"IceCube\"].T)\n",
    "    naming = \"\"\n",
    "    for ident, lt_factor in series.items():\n",
    "        if ident==\"identifier\": continue\n",
    "        if lt_factor==0 : continue\n",
    "        print(ident)\n",
    "        aeff_factor += aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME * lt_factor\n",
    "    # asimov = expectation of perfect experiment\n",
    "    k_i = asimov_data(aeff_factor, shape, verbose=verbose)  \n",
    "\n",
    "    # global min\n",
    "    out = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[shape][\"guess\"],\n",
    "        bounds=shape_params[shape][\"bounds\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "    )\n",
    "    # check that the TS at the fit minimum is close to the TS of the baseline params\n",
    "    baseline_ts_check = np.isclose(\n",
    "        out[1], spectral_ts_func(\n",
    "            shape_params[shape][\"baseline\"],\n",
    "            aeff_factor, emids, E_NORM, k_i, shape\n",
    "        ), rtol=1E-2\n",
    "    )\n",
    "    print(\"TS asimov check:\", \"OK\" if baseline_ts_check else \"not OK :(\")\n",
    "    # best fit powerlaw as null hypothesis     \n",
    "    out_pl = fmin_l_bfgs_b(\n",
    "        spectral_ts_func,\n",
    "        x0=shape_params[\"powerlaw\"][\"guess\"],\n",
    "        bounds=shape_params[\"powerlaw\"][\"bounds\"],\n",
    "        approx_grad=True,\n",
    "        args=(aeff_factor, emids, E_NORM, k_i, \"powerlaw\")\n",
    "    )\n",
    "    pval = chi2.sf(out_pl[1] - out[1], 1)\n",
    "    sigma = erfinv(1 - pval) * np.sqrt(2)\n",
    "    print(\"P-VALUE:\", pval, \", SIGNIFICANCE:\", sigma)\n",
    "    pvals.append({\"identifier\": series.identifier, #str(idx) + \", \" + \n",
    "                  \"idx\": idx, \"pval\": pval, r\"Significance in $\\sigma$\": sigma})\n",
    "\n",
    "pval_df = pd.DataFrame(pvals)\n",
    "pval_df[r\"$-\\log_{10}$(p-value)\"] = -np.log10(pval_df.pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "label_size = \"x-small\"\n",
    "# ICECUBE\n",
    "ax.plot(\n",
    "    pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    pval_df.loc[[0, 1, 2]][r\"Significance in $\\sigma$\"],\n",
    "    ls=contour_formats[\"IceCube\"][\"linestyles\"], color=poles[\"IceCube\"][\"color\"],\n",
    "    marker=\"d\", label=\"IceCube\", ms=10\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    y=pval_df.loc[[0, 1, 2]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[:3], s=150, zorder=10, marker=\"d\"\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[0][\"identifier\"], \n",
    "    y=pval_df.loc[0][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  10yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[1][\"identifier\"], \n",
    "    y=pval_df.loc[1][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +10yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[2][\"identifier\"], \n",
    "    y=pval_df.loc[2][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +30yr\", fontsize=label_size\n",
    ")\n",
    "\n",
    "## PLENUM-1\n",
    "ax.plot(\n",
    "    pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    pval_df.loc[[3, 4, 5]][r\"Significance in $\\sigma$\"],\n",
    "    ls=poles[\"Plenum-1\"][\"ls\"], color=poles[\"Plenum-1\"][\"color\"],\n",
    "    marker=\"s\", label=\"IceCube + Plenum-1\", ms=10\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    y=pval_df.loc[[3, 4, 5]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"s\"\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[3][\"identifier\"], \n",
    "    y=pval_df.loc[3][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +2yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[4][\"identifier\"], \n",
    "    y=pval_df.loc[4][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +5yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[5][\"identifier\"], \n",
    "    y=pval_df.loc[5][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +10yr\", fontsize=label_size\n",
    ")\n",
    "\n",
    "\n",
    "## PLENUM-2\n",
    "ax.plot(\n",
    "    pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    pval_df.loc[[6, 7, 8]][r\"Significance in $\\sigma$\"],\n",
    "    ls=poles[\"Plenum-2\"][\"ls\"], color=poles[\"Plenum-2\"][\"color\"],\n",
    "    marker=\"o\", label=\"IceCube + Plenum-2\", ms=10\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    y=pval_df.loc[[6, 7, 8]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"o\"\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[6][\"identifier\"], \n",
    "    y=pval_df.loc[6][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +2yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[7][\"identifier\"], \n",
    "    y=pval_df.loc[7][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +5yr\", fontsize=label_size\n",
    ")\n",
    "ax.text(\n",
    "    x=pval_df.loc[8][\"identifier\"], \n",
    "    y=pval_df.loc[8][r\"Significance in $\\sigma$\"],\n",
    "    s=\"  +10yr\", fontsize=label_size\n",
    ")\n",
    "\n",
    "ax.set_xlim(-1, 10)\n",
    "ax.set_ylim(1, 6)\n",
    "ax.set_xticks([])\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.set_title(\"Power law with cutoff\", fontsize=\"small\")\n",
    "ax.set_xlabel(\"Livetime/Detectors\")\n",
    "ax.set_ylabel(r\"Significance in $\\sigma$\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/cutoff_sigma_vs_det_talk.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "ax.plot(\n",
    "    pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    pval_df.loc[[0, 1, 2]][r\"Significance in $\\sigma$\"],\n",
    "    ls=contour_formats[\"IceCube\"][\"linestyles\"], color=poles[\"IceCube\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    y=pval_df.loc[[0, 1, 2]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[:3], s=150, zorder=10, marker=\"d\"\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    pval_df.loc[[3, 4, 5]][r\"Significance in $\\sigma$\"],\n",
    "    ls=poles[\"Plenum-1\"][\"ls\"], color=poles[\"Plenum-1\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    y=pval_df.loc[[3, 4, 5]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"s\"\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    pval_df.loc[[6, 7, 8]][r\"Significance in $\\sigma$\"],\n",
    "    ls=poles[\"Plenum-2\"][\"ls\"], color=poles[\"Plenum-2\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    y=pval_df.loc[[6, 7, 8]][r\"Significance in $\\sigma$\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"o\"\n",
    ")\n",
    "\n",
    "\n",
    "#ax.set_ylim(0, 5.5)\n",
    "ax.set_title(\"Power law with cutoff\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(r\"Significance in $\\sigma$\")\n",
    "plt.xticks(rotation=65, fontsize=\"small\", ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/cutoff_sigma_vs_det.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(\n",
    "    pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    pval_df.loc[[0, 1, 2]][r\"$-\\log_{10}$(p-value)\"],\n",
    "    ls=contour_formats[\"IceCube\"][\"linestyles\"], color=poles[\"IceCube\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[0, 1, 2]][\"identifier\"], \n",
    "    y=pval_df.loc[[0, 1, 2]][r\"$-\\log_{10}$(p-value)\"], \n",
    "    c=many_colors[:3], s=150, zorder=10, marker=\"d\"\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    pval_df.loc[[3, 4, 5]][r\"$-\\log_{10}$(p-value)\"],\n",
    "    ls=poles[\"Plenum-1\"][\"ls\"], color=poles[\"Plenum-1\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[3, 4, 5]][\"identifier\"], \n",
    "    y=pval_df.loc[[3, 4, 5]][r\"$-\\log_{10}$(p-value)\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"s\"\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    pval_df.loc[[6, 7, 8]][r\"$-\\log_{10}$(p-value)\"],\n",
    "    ls=poles[\"Plenum-2\"][\"ls\"], color=poles[\"Plenum-2\"][\"color\"]\n",
    ")\n",
    "ax.scatter(\n",
    "    x=pval_df.loc[[6, 7, 8]][\"identifier\"], \n",
    "    y=pval_df.loc[[6, 7, 8]][r\"$-\\log_{10}$(p-value)\"], \n",
    "    c=many_colors[6:], s=150, zorder=10, marker=\"o\"\n",
    ")\n",
    "\n",
    "ax.set_title(\"Power law with cutoff\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(r\"$-\\log_{10}$(p-value)\")\n",
    "plt.xticks(rotation=65, fontsize=\"small\", ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/cutoff_pval_vs_det.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance vs cutoff value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_names = {\n",
    "    \"IceCube\": \"IceCube\",\n",
    "    \"Plenum-1\": r\"IceCube + PLE$\\nu$M-1\",\n",
    "    \"Plenum-2\": r\"IceCube + PLE$\\nu$M-2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pvals = []\n",
    "cutoff_vals = np.round(np.arange(5.0, 8.1, step=0.2), 1)\n",
    "for e_cut in cutoff_vals:\n",
    "    for li, ident in enumerate(idents):\n",
    "        shape = \"powerlaw with cutoff\"\n",
    "        aeff_factor = aeff_eval_e_sd(aeff_2d[ident], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "        if \"Plenum\" in ident:\n",
    "            aeff_factor += aeff_eval_e_sd(aeff_2d[\"IceCube\"], sindec_width, ewidth, ra_width) * LIVETIME\n",
    "        # asimov = expectation of perfect experiment\n",
    "        shp_params = np.copy(shape_params[shape][\"baseline\"])\n",
    "        shp_params[-1] = e_cut\n",
    "        k_i = asimov_data(\n",
    "            aeff_factor, shape, verbose=False, shp_params=shp_params)\n",
    "\n",
    "        # global min\n",
    "        out = fmin_l_bfgs_b(\n",
    "            spectral_ts_func,\n",
    "            x0=shape_params[shape][\"guess\"],\n",
    "            bounds=shape_params[shape][\"bounds\"],\n",
    "            approx_grad=True,\n",
    "            args=(aeff_factor, emids, E_NORM, k_i, shape)\n",
    "        )\n",
    "        # check that the TS at the fit minimum is close to the TS of the baseline params\n",
    "        reference = spectral_ts_func(\n",
    "            shp_params,\n",
    "            aeff_factor, emids, E_NORM, k_i, shape\n",
    "        )\n",
    "        baseline_ts_check = np.isclose(out[1], reference, rtol=1E-2)\n",
    "        print(\"TS asimov check:\", \"OK\" if baseline_ts_check else \"not OK :(\")\n",
    "        if not baseline_ts_check:\n",
    "            print(\"e_cut:\", shp_params[-1])\n",
    "            print(\"fit: \", out[1], \", reference:\", reference)\n",
    "        # best fit powerlaw as null hypothesis     \n",
    "        out_pl = fmin_l_bfgs_b(\n",
    "            spectral_ts_func,\n",
    "            x0=shape_params[\"powerlaw\"][\"guess\"],\n",
    "            bounds=shape_params[\"powerlaw\"][\"bounds\"],\n",
    "            approx_grad=True,\n",
    "            args=(aeff_factor, emids, E_NORM, k_i, \"powerlaw\")\n",
    "        )\n",
    "        pval = chi2.sf(out_pl[1] - out[1], 1)\n",
    "        significance = erfinv(1 - pval) * np.sqrt(2)\n",
    "        # print(\"P-VALUE:\", pval, \", SIGNIFICANCE:\", significance)\n",
    "        pvals.append({\"ident\": print_names[ident], \"pval\": pval, \n",
    "                      r\"Significance in $\\sigma$\": significance, \n",
    "                      r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\": e_cut,\n",
    "                      r\"Conv_PL\": out_pl[0][0],\n",
    "                      r\"$\\gamma_{PL}$\": out_pl[0][1],\n",
    "                      r\"$\\Phi_{0,PL}$\": out_pl[0][2],\n",
    "                      r\"Conv\": out[0][0],\n",
    "                      r\"$\\gamma$\": out[0][1],\n",
    "                      r\"$\\Phi_{0}$\": out[0][2],\n",
    "                      r\"$E_{\\rm cut}$\": out[0][3]\n",
    "                     })\n",
    "\n",
    "pval_df = pd.DataFrame(pvals)\n",
    "pval_df[r\"$-\\log_{10}$(p-value)\"] = -np.log10(pval_df.pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$-\\log_{10}$(p-value)\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\", \n",
    "    palette=many_colors[[1, 7, 8]], linestyles=[\"--\", \"-.\", \"-\"], markers=[\"d\", \"s\", \"o\"]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\") #, fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=1) #, fontsize=\"x-small\")\n",
    "ax.set_ylim(0, 14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plots/cutoff_pval_vs_cutoff.pdf\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"Significance in $\\sigma$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\", \n",
    "    palette=many_colors[[1, 7, 8]], linestyles=[\"--\", \"-.\", \"-\"], markers=[\"d\", \"s\", \"o\"]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\") #, fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=1) #, fontsize=\"x-small\")\n",
    "ax.set_ylim(0, 9)\n",
    "f.tight_layout()\n",
    "plt.savefig(\"../plots/cutoff_sigma_vs_cutoff.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check that parameter fits are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$\\gamma_{PL}$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\", \n",
    "    palette=many_colors[[1, 7, 8]], linestyles=[\"-\", \"-.\", \"-\"], markers=[\"d\", \"s\", \"o\"]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=1, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$\\Phi_{0,PL}$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=4, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"Conv_PL\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=4, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$\\gamma$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=1, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$\\Phi_{0}$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=4, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"Conv\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=4, fontsize=\"x-small\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "ax = sns.pointplot(\n",
    "    data=pval_df, hue=\"ident\", ax=ax,\n",
    "    y=r\"$E_{\\rm cut}$\", x=r\"$\\log_{10}(E_{\\rm cut}/{\\rm GeV})$\",\n",
    "    palette=many_colors[[1, 4, 7]]\n",
    ")\n",
    "ax.set_title(\"Power law with cutoff: 10yr livetime\", fontsize=\"small\")\n",
    "ax.set_xticks(np.arange(0, len(cutoff_vals), step=5))\n",
    "ax.legend(loc=4, fontsize=\"x-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
